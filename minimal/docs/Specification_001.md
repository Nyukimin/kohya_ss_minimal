了解です。
同僚向けに「**なぜこのタブを追加したのか（背景）**」と「**何ができて、何をしないのか（仕様）**」が**誤解なく伝わる**ことを最優先に、テキストでまとめます。
そのまま Slack / Confluence / README / メールに貼れる粒度です。

---

## 1. 背景（なぜタブを追加したのか）

### 現状の課題

kohya-ss の既存GUIは非常に高機能だが、

* パラメータ数が多く、**LoRA作成で毎回触る項目と、ほぼ触らない項目が混在**している
* 特に **SDXL向け顔LoRA** では、
  実際に調整するのは「ごく一部の数値」だけなのに、
  それ以外の設定が視界ノイズになりやすい
* repeat（学習回数）や caption など、**GUI外のルール依存**が多く、
  手順を知っていないと事故りやすい

結果として、

* 手順の属人化
* 設定ミスによる学習失敗
* 「前回どうやったっけ？」問題

が起きやすい状態だった。

---

## 2. 今回のタブ追加の狙い（設計思想）

### 目的

* **SDXL顔LoRAを、毎回同じ品質・同じ考え方で作れる状態にする**
* 「毎回触る数個のパラメータ」だけを明示的に操作できるようにする
* kohya-ss 本体の設計を壊さず、**いつでも切り捨て可能**な拡張にする

### やらないこと（重要）

* kohya-ss の既存LoRAタブを置き換えない
* 学習ロジック（train_network.py）には手を入れない
* optimizer や scheduler などの研究寄りパラメータは触らせない

→ **あくまで「操作を簡単にする補助タブ」**

---

## 3. 技術的な位置づけ（誤解防止）

* このタブは **独自フォークの custom タブ**
* kohya-ss の **GUI拡張レイヤ**にのみ存在する
* 学習自体は **既存の kohya-ss の仕組みをそのまま使う**

つまり、

> 「新しい学習方式を追加した」のではなく
> 「既存の学習方式を、間違いにくいUIで包んだ」

という位置づけ。

### 3.1 「Start Training」ボタンの挙動（設計思想）

**Minimalタブの「Start Training」ボタンは、LoRAタブのTrainingタブの「Start Training」ボタンの挙動を模倣する。**

これは、Minimalタブの設計思想を実現するための重要な要件です。

#### 処理フロー

Minimalタブの「Start Training」ボタン押下時の処理フロー：

1. **Minimalタブの「Start Training」押下**
   - MinimalタブのUIから16個のパラメータを取得

2. **Minimalパラメータ生成**
   - MinimalタブのUI入力値から、16個のパラメータを生成

3. **Trainingパラメータ生成**
   - 既存のTrainingタブと同じように、全243個のパラメータをデフォルト値で生成
   - Trainingタブの `settings_list` 構築ロジックと同じ方法で、デフォルト値を生成

4. **Minimalパラメータマージ**
   - Trainingパラメータ（243個）に、Minimalパラメータ（16個）を上書き
   - Minimalタブで設定した値が優先される

5. **settings_list の構築**
   - マージ後のパラメータセットから、Trainingタブと同じ順序で `settings_list` を構築

6. **トレーニング開始**
   - 既存の `train_model` 関数を、Trainingタブと同じ方法で呼び出す
   - 以降の処理（バリデーション、コマンド構築、プロセス起動）は、Trainingタブと同じフロー

#### 設計思想との整合性

この実装パターンは、以下の設計思想と完全に合致しています：

- **既存の学習方式をそのまま使う**: `train_model` 関数は既存のまま使用
- **GUI拡張レイヤにのみ存在**: パラメータ生成部分のみを置き換える
- **いつでも切り捨て可能**: Trainingタブと同じ実装パターンなので、理解しやすく保守しやすい

詳細は [Design_Requirement_001.md](Design_Requirement_001.md) を参照してください。

---

## 4. タブの対象範囲（スコープ）

### 対象

* SDXL 専用
* 顔LoRA（実用向け、過学習させない前提）

### 想定ユーザー

* kohya-ss を触ったことはある
* だが「全部の項目を毎回理解したい」わけではない
* **再現性重視・作業効率重視**

---

## 5. タブで「できること」（仕様）

### ① ベースモデル（Checkpoint）の切り替え

* SDXL用 checkpoint を選択 or パス指定
* デフォルトは config で決めるが、UIから変更可能

### ② 学習データ指定

* 学習データの **親フォルダ** を指定
* フォルダ名に repeat を書く方式は使わない

### ③ Repeat（学習回数）の明示指定

* `num_repeats` を **数値としてUIから指定**
* 内部的には `dataset_config.toml` を生成して使用
* フォルダ名ルールに依存しない

### ④ 学習量の制御

* Epoch
* Max train steps（こちらを優先）
* 「途中で止める前提」の設計

### ⑤ 主要学習パラメータ

* U-Net Learning Rate
* Text Encoder Learning Rate
* LoRA Rank / Alpha
* Resolution（顔LoRA前提で固定寄り）

### ⑥ Caption一括生成（重要）

* 固定 caption を **全画像に一括生成**
* 既存 `.txt` がある場合は **必ず上書き確認**
* 学習前の事故を防ぐための補助機能

### ⑦ 出力設定

* 出力ファイル名
* 出力フォルダ

---

## 6. タブで「できないこと」（意図的な制限）

以下は **あえてUIに出していない**。

* optimizer / lr scheduler の変更
* network_module / network_args の詳細設定
* 正則化画像（reg images）
* 複数 dataset / subset
* フォルダ名 repeat 方式

理由：

* ここを触り始めると「研究モード」に入る
* 今回の目的は **安定した量産と再現性**

---

## 7. 安全性・切り捨て性

* 実装は `custom/` ディレクトリ配下に閉じている
* upstream 側の改造は **最小限のフックのみ**
* custom を削除 or 無効化すれば、即元の kohya-ss に戻る

→ **実験的に入れても、後腐れがない**

---

## 8. まとめ（同僚向け一文要約）

> このタブは
> **「SDXL顔LoRAを、毎回同じ考え方・同じ品質で作るために、
> 本当に必要なパラメータだけを安全に操作できる補助UI」**
> です。
>
> 学習の仕組みは変えていません。
> 変えたのは「操作の迷い」と「事故の起きやすさ」だけです。

---
