import gradio as gr
import os
from pathlib import Path
from typing import Any
import logging

# ãƒ­ã‚°è¨­å®šã‚’æœ€åˆã«å®šç¾©
log = logging.getLogger(__name__)

# Minimalç”¨ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®šã‚’èª­ã¿è¾¼ã¿

from minimal.presets import (
    MINIMAL_DEFAULT_CONFIG,
    SDXL_FACE_LORA_FIXED,
    RESOLUTION_CHOICES,
    BATCH_SIZE_CHOICES,
    SAVE_MODEL_AS_CHOICES,
    SAVE_PRECISION_CHOICES
)

# tomlãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import toml

def load_user_config() -> dict:
    """
    config.tomlã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚’å‹•çš„ã«èª­ã¿è¾¼ã‚€
    
    Design_Requirement_002: Tab.select()æ™‚ã«å‘¼ã³å‡ºã•ã‚Œã€
    MINIMAL_DEFAULT_CONFIGã«ä¸Šæ›¸ãã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹
    
    Returns:
        dict: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šï¼ˆãƒ•ãƒ©ãƒƒãƒˆåŒ–æ¸ˆã¿ï¼‰ã€‚èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯ç©ºã®è¾æ›¸
    """
    config_path = Path(__file__).parent / "config.toml"
    try:
        if config_path.exists():
            config_data = toml.load(config_path)
            # TOMLã®éšå±¤æ§‹é€ ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–
            user_config = {
                **config_data.get('model', {}),
                **config_data.get('training_data', {}),
                **config_data.get('training_params', {}),
                **config_data.get('output', {})
            }
            log.info(f"Loaded user config from {config_path}")
            return user_config
        else:
            log.info("config.toml not found, using default values")
            return {}
    except Exception as e:
        log.warning(f"Failed to load config.toml: {e}")
        return {}

# ãƒ•ã‚©ãƒ«ãƒ€é¸æŠæ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from kohya_gui.common_gui import get_folder_path, get_file_path

# kohya-ssã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚¢ã‚¤ã‚³ãƒ³
folder_symbol = "\U0001f4c2"  # ğŸ“‚
save_style_symbol = "\U0001f4be"  # ğŸ’¾
document_symbol = "\U0001F4C4"  # ğŸ“„

class SDXLSimpleTab:
    """
    SDXLé¡”LoRAå°‚ç”¨ã®ç°¡æ˜“UIã‚¿ãƒ–
    æ—¢å­˜ã®LoRAã‚¿ãƒ–ã¨åŒã˜å‡¦ç†ã‚’ã€ç°¡æ½”ãªUIã§æ“ä½œã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    """
    
    def __init__(self, headless: bool = False, config: Any = None, use_shell_flag: bool = False):
        self.headless = headless
        self.config = config
        self.use_shell_flag = use_shell_flag
        self.config_path = Path(__file__).parent / "config.toml"
        
    def create_ui(self):
        """UIä½œæˆï¼ˆAccordionå½¢å¼ã€æ—¢å­˜ã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹ï¼‰"""
        with gr.Column(variant="compact"):
            gr.Markdown("**SDXLé¡”LoRAå°‚ç”¨ã®ç°¡æ˜“ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹** - å¿…è¦æœ€å°é™ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®‰å…¨ã«å­¦ç¿’")
            
            # Model Source
            with gr.Accordion("Model Source", open=True):
                with gr.Row():
                    self.pretrained_model_name_or_path = gr.Textbox(
                        label="SDXL Checkpoint path",
                        placeholder="SDXLãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ (.safetensors or .ckpt)",
                        value=MINIMAL_DEFAULT_CONFIG.get('pretrained_model_name_or_path', ''),
                        interactive=True,
                        scale=3
                    )
                    model_file_button = gr.Button(
                        folder_symbol,
                        elem_id="open_folder_small",
                        elem_classes=["tool"],
                        visible=(not self.headless)
                    )
                
                with gr.Row():
                    self.save_model_as = gr.Dropdown(
                        label="Save trained model as",
                        choices=SAVE_MODEL_AS_CHOICES,
                        value=MINIMAL_DEFAULT_CONFIG.get('save_model_as', 'safetensors')
                    )
                    self.save_precision = gr.Dropdown(
                        label="Save precision", 
                        choices=SAVE_PRECISION_CHOICES,
                        value=MINIMAL_DEFAULT_CONFIG.get('save_precision', 'fp16')
                    )
            
            # Training Data
            with gr.Accordion("Training Data", open=True):
                with gr.Row():
                    self.train_data_dir = gr.Textbox(
                        label="Image folder",
                        placeholder="å­¦ç¿’ç”»åƒãŒå«ã¾ã‚Œã‚‹ãƒ•ã‚©ãƒ«ãƒ€",
                        value=MINIMAL_DEFAULT_CONFIG.get('train_data_dir', ''),
                        interactive=True,
                        scale=3
                    )
                    image_folder_button = gr.Button(
                        folder_symbol,
                        elem_id="open_folder_small",
                        elem_classes=["tool"],
                        visible=(not self.headless)
                    )
                
                with gr.Row():
                    self.max_resolution = gr.Dropdown(
                        label="Resolution",
                        choices=RESOLUTION_CHOICES,
                        value=MINIMAL_DEFAULT_CONFIG.get('max_resolution', '512,512'),
                        info="å­¦ç¿’è§£åƒåº¦ï¼ˆé¡”LoRAã¯512x512æ¨å¥¨ï¼‰"
                    )
                    self.train_batch_size = gr.Dropdown(
                        label="Batch size",
                        choices=BATCH_SIZE_CHOICES,
                        value=MINIMAL_DEFAULT_CONFIG.get('train_batch_size', 1),
                        info="ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆ1æ¨å¥¨ï¼‰"
                    )
            
            # Caption Generation
            with gr.Accordion("Caption Generation", open=False):
                gr.Markdown("**å›ºå®šã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’å…¨ç”»åƒã«ä¸€æ‹¬ç”Ÿæˆ** - å­¦ç¿’å‰ã®äº‹æ•…ã‚’é˜²ããŸã‚ã®è£œåŠ©æ©Ÿèƒ½")
                gr.Markdown("*ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ï¼ˆImage folderï¼‰ã«æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã«è‡ªå‹•çš„ã«ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¾ã™*")
                with gr.Row():
                    self.caption_text = gr.Textbox(
                        label="Caption text",
                        placeholder="ä¾‹: character_name, face, portrait",
                        value=MINIMAL_DEFAULT_CONFIG.get('caption_text', ''),
                        info="å…¨ç”»åƒã«é©ç”¨ã™ã‚‹å›ºå®šã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ",
                        lines=2
                    )
                with gr.Row():
                    self.caption_overwrite = gr.Checkbox(
                        label="Overwrite existing captions",
                        value=False,
                        info="æ—¢å­˜ã®.txtãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã«ä¸Šæ›¸ãã™ã‚‹ï¼ˆâš ï¸ æ³¨æ„: æ—¢å­˜ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãŒå¤±ã‚ã‚Œã¾ã™ï¼‰"
                    )
                with gr.Row():
                    self.generate_captions_button = gr.Button(
                        "Generate caption files",
                        variant="secondary",
                        scale=1
                    )
                    self.caption_result = gr.Textbox(
                        label="Caption generation result",
                        value="",
                        interactive=False,
                        lines=3,
                        max_lines=5,
                        scale=2
                    )
            
            # Training Parameters  
            with gr.Accordion("Training Parameters", open=True):
                with gr.Row():
                    self.learning_rate = gr.Textbox(
                        label="Learning rate",
                        value=str(MINIMAL_DEFAULT_CONFIG.get('learning_rate', 0.0001)),
                        info="å­¦ç¿’ç‡ï¼ˆU-Netç”¨ï¼‰"
                    )
                    # Text encoder learning rateã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨ˆç®—ï¼ˆæŒ‡æ•°è¡¨è¨˜ã‚’é¿ã‘ã‚‹ãŸã‚æ˜ç¤ºçš„ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
                    text_encoder_lr_default = MINIMAL_DEFAULT_CONFIG.get('text_encoder_lr', MINIMAL_DEFAULT_CONFIG.get('learning_rate', 0.0001) * 0.5)
                    # æŒ‡æ•°è¡¨è¨˜ã‚’é¿ã‘ã¦å°æ•°è¡¨è¨˜ã§è¡¨ç¤ºï¼ˆå°æ•°ç‚¹ä»¥ä¸‹5æ¡ã¾ã§ï¼‰
                    text_encoder_lr_str = f"{float(text_encoder_lr_default):.5f}".rstrip('0').rstrip('.')
                    self.text_encoder_lr = gr.Textbox(
                        label="Text encoder learning rate",
                        value=text_encoder_lr_str,
                        info="Text Encoderå­¦ç¿’ç‡"
                    )
                
                with gr.Row():
                    self.network_dim = gr.Number(
                        label="LoRA Rank (dim)",
                        value=MINIMAL_DEFAULT_CONFIG.get('network_dim', 16),
                        minimum=1,
                        maximum=128,
                        step=1,
                        info="LoRAã®æ¬¡å…ƒæ•°"
                    )
                    self.network_alpha = gr.Number(
                        label="LoRA Alpha",
                        value=MINIMAL_DEFAULT_CONFIG.get('network_alpha', 16),
                        minimum=1,
                        maximum=128,
                        step=1,
                        info="LoRAã®ã‚¢ãƒ«ãƒ•ã‚¡å€¤"
                    )
                
                with gr.Row():
                    self.epoch = gr.Number(
                        label="Epochs",
                        value=MINIMAL_DEFAULT_CONFIG.get('epoch', 6),
                        minimum=1,
                        maximum=100,
                        step=1
                    )
                    self.max_train_steps = gr.Number(
                        label="Max train steps",
                        value=MINIMAL_DEFAULT_CONFIG.get('max_train_steps', 1600),
                        minimum=0,
                        step=100,
                        info="0 = epochæ•°ã®ã¿ä½¿ç”¨"
                    )
                
                with gr.Row():
                    self.cache_latents = gr.Checkbox(
                        label="Cache latents",
                        value=MINIMAL_DEFAULT_CONFIG.get('cache_latents', True),
                        info="latentsã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦é«˜é€ŸåŒ–"
                    )
                    self.cache_latents_to_disk = gr.Checkbox(
                        label="Cache latents to disk",
                        value=MINIMAL_DEFAULT_CONFIG.get('cache_latents_to_disk', False),
                        info="ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§VRAMç¯€ç´„"
                    )
            
            # Output
            with gr.Accordion("Output", open=True):
                with gr.Row():
                    self.output_name = gr.Textbox(
                        label="Output name",
                        placeholder="character_name_lora",
                        value=MINIMAL_DEFAULT_CONFIG.get('output_name', ''),
                        info="å‡ºåŠ›ã™ã‚‹LoRAãƒ¢ãƒ‡ãƒ«ã®åå‰"
                    )
                
                with gr.Row():
                    self.output_dir = gr.Textbox(
                        label="Output folder",
                        placeholder="å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€",
                        value=MINIMAL_DEFAULT_CONFIG.get('output_dir', './outputs'),
                        scale=3
                    )
                    output_folder_button = gr.Button(
                        folder_symbol,
                        elem_id="open_folder_small",
                        elem_classes=["tool"],
                        visible=(not self.headless)
                    )
            
            # Training Control
            with gr.Accordion("Training", open=True):
                with gr.Row():
                    self.train_button = gr.Button(
                        "Start training",
                        variant="primary",
                        scale=2
                    )
                    self.save_config_button = gr.Button(
                        "Save Config",
                        variant="secondary",
                        scale=1,
                        interactive=True  # å¸¸ã«æœ‰åŠ¹
                    )
                    self.stop_button = gr.Button(
                        "Stop training",
                        variant="stop",
                        scale=1
                    )
                
                # hidden ã®çŠ¶æ…‹å¤‰æ•°ï¼ˆãƒœã‚¿ãƒ³çŠ¶æ…‹ç®¡ç†ç”¨ï¼‰
                import time
                self.run_state = gr.Textbox(value=str(time.time()), visible=False)
                
                # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒãƒªãƒ¼ï¼ˆé–‹å§‹æ™‚ã«è¡¨ç¤ºï¼‰
                self.training_summary = gr.Textbox(
                    label="Training Summary",
                    value="",
                    lines=8,
                    max_lines=12,
                    interactive=False,
                    show_copy_button=True
                )
                
                # ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ï¼‰
                self.epoch_stats = gr.Textbox(
                    label="ğŸ“ˆ Epoch Statistics (Loss & Time)",
                    value="Training not started yet...",
                    lines=6,
                    max_lines=10,
                    interactive=False,
                    show_copy_button=True
                )
                
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ãƒ­ã‚°
                self.output_log = gr.Textbox(
                    label="Training Progress (Live)",
                    value="Waiting for training to start...",
                    lines=10,
                    max_lines=15,
                    interactive=False,
                    show_copy_button=True,
                    autoscroll=True
                )
                
                # å®šæœŸæ›´æ–°ç”¨ã‚¿ã‚¤ãƒãƒ¼ï¼ˆ1ç§’é–“éš”ï¼‰
                self.progress_timer = gr.Timer(value=1, active=False)
            
            # ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š
            # ãƒ•ã‚©ãƒ«ãƒ€é¸æŠãƒœã‚¿ãƒ³
            model_file_button.click(
                fn=lambda: get_file_path(
                    default_extension=".safetensors", 
                    extension_name="SDXL Model files"
                ),
                outputs=[self.pretrained_model_name_or_path],
                show_progress=False
            )
            
            image_folder_button.click(
                fn=get_folder_path,
                outputs=[self.train_data_dir],
                show_progress=False
            )
            
            output_folder_button.click(
                fn=get_folder_path,
                outputs=[self.output_dir],
                show_progress=False
            )
            
            # è¨­å®šä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆæ˜ç¤ºä¿å­˜ãƒ•ãƒ©ã‚°ä»˜ãï¼‰
            explicit_save_flag = gr.State(True)

            self.save_config_button.click(
                fn=self.save_config_and_reset_button,
                inputs=[explicit_save_flag] + self._get_all_inputs(),
                outputs=[self.output_log, self.save_config_button],
                show_progress=False
            )
            
            # è‡ªå‹•ä¿å­˜ã¯å»ƒæ­¢ï¼ˆDesign_Requirement_002ï¼‰
            # ä»£ã‚ã‚Šã«ã€å€¤å¤‰æ›´æ™‚ã«Save Configãƒœã‚¿ãƒ³ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
            # Tab.select() ã«ã‚ˆã‚‹å¤‰æ›´ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ãŸã‚ã€config.toml ã¨æ¯”è¼ƒ
            change_components = [
                self.pretrained_model_name_or_path,
                self.train_data_dir,
                self.output_name,
                self.output_dir,
                self.learning_rate,
                self.text_encoder_lr,
                self.network_dim,
                self.network_alpha,
                self.epoch,
                self.max_train_steps,
                self.max_resolution,
                self.train_batch_size,
                self.cache_latents,
                self.cache_latents_to_disk,
                self.save_model_as,
                self.save_precision
            ]
            
            for component in change_components:
                component.change(
                    fn=self._check_config_changed,
                    inputs=self._get_all_inputs(),
                    outputs=[self.save_config_button],
                    show_progress=False
                )
            
            # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆãƒœã‚¿ãƒ³
            self.generate_captions_button.click(
                fn=self.generate_captions,
                inputs=[
                    self.caption_text,
                    self.train_data_dir,
                    self.caption_overwrite
                ],
                outputs=[self.caption_result],
                show_progress=True
            )
            
            # å­¦ç¿’é–‹å§‹ãƒœã‚¿ãƒ³
            # start_training() ã¯ (train_button, stop_button, run_state, training_summary, timer) ã‚’è¿”ã™
            from kohya_gui.lora_gui import executor
            
            self.train_button.click(
                fn=self.start_training,
                inputs=self._get_all_inputs(),
                outputs=[self.train_button, self.stop_button, self.run_state, self.training_summary, self.progress_timer],
                show_progress=True
            )
            
            # ã‚¿ã‚¤ãƒãƒ¼ã§å®šæœŸçš„ã«é€²æ—ãƒ­ã‚°ã‚’æ›´æ–°
            # ã‚¿ã‚¤ãƒãƒ¼ã§å®šæœŸçš„ã«é€²æ—ãƒ­ã‚°ã¨ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆã‚’æ›´æ–°
            self.progress_timer.tick(
                fn=self._update_progress_log,
                outputs=[self.output_log, self.epoch_stats, self.progress_timer],
                show_progress=False
            )
            
            # run_state ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ‚äº†ã‚’å¾…ã£ã¦ãƒœã‚¿ãƒ³çŠ¶æ…‹ã‚’å¾©å…ƒ
            self.run_state.change(
                fn=self._wait_and_stop_timer,
                outputs=[self.train_button, self.stop_button, self.progress_timer, self.output_log, self.epoch_stats],
                show_progress=False
            )
            
            # å­¦ç¿’åœæ­¢ãƒœã‚¿ãƒ³
            self.stop_button.click(
                fn=self._stop_training,
                outputs=[self.train_button, self.stop_button, self.progress_timer, self.output_log, self.epoch_stats],
                show_progress=False
            )
    
    def _parse_epoch_stats(self, full_output: str) -> str:
        """ãƒ­ã‚°ã‹ã‚‰ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®çµ±è¨ˆæƒ…å ±ã‚’æŠ½å‡º"""
        import re
        
        lines = full_output.split('\n')
        epoch_stats = []
        current_epoch = 0
        epoch_losses = {}
        epoch_times = {}
        start_time = None
        last_epoch_time = None
        
        for line in lines:
            # ã‚¨ãƒãƒƒã‚¯é–‹å§‹ã‚’æ¤œå‡º: "epoch 1/6" ãƒ‘ã‚¿ãƒ¼ãƒ³
            epoch_match = re.search(r'epoch\s+(\d+)/(\d+)', line, re.IGNORECASE)
            if epoch_match:
                new_epoch = int(epoch_match.group(1))
                if new_epoch != current_epoch:
                    if current_epoch > 0 and last_epoch_time:
                        # å‰ã®ã‚¨ãƒãƒƒã‚¯ã®æ™‚é–“ã‚’è¨˜éŒ²
                        import time
                        now = time.time()
                        if current_epoch not in epoch_times:
                            epoch_times[current_epoch] = now - last_epoch_time
                    current_epoch = new_epoch
                    import time
                    last_epoch_time = time.time()
            
            # losså€¤ã‚’æ¤œå‡º: "loss: 0.0543" ã¾ãŸã¯ "loss=0.0543" ãƒ‘ã‚¿ãƒ¼ãƒ³
            loss_match = re.search(r'loss[:\s=]+([0-9.]+)', line, re.IGNORECASE)
            if loss_match and current_epoch > 0:
                loss_val = float(loss_match.group(1))
                if current_epoch not in epoch_losses:
                    epoch_losses[current_epoch] = []
                epoch_losses[current_epoch].append(loss_val)
            
            # ã‚¹ãƒ†ãƒƒãƒ—é€²æ—ã‚’æ¤œå‡º: "step 100/450" ã¾ãŸã¯é€²æ—ãƒãƒ¼
            step_match = re.search(r'(\d+)/(\d+)\s*\[', line)
            if step_match:
                current_step = int(step_match.group(1))
                total_steps = int(step_match.group(2))
        
        # çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ
        if not epoch_losses and current_epoch == 0:
            return ""
        
        stats_lines = [
            "",
            "ğŸ“ˆ Epoch Statistics:",
            "-" * 40
        ]
        
        for epoch in sorted(epoch_losses.keys()):
            losses = epoch_losses[epoch]
            avg_loss = sum(losses) / len(losses) if losses else 0
            min_loss = min(losses) if losses else 0
            max_loss = max(losses) if losses else 0
            
            time_str = ""
            if epoch in epoch_times:
                mins = int(epoch_times[epoch] // 60)
                secs = int(epoch_times[epoch] % 60)
                time_str = f" | Time: {mins}m {secs}s"
            
            stats_lines.append(
                f"  Epoch {epoch}: Avg Loss={avg_loss:.4f} (Min={min_loss:.4f}, Max={max_loss:.4f}){time_str}"
            )
        
        # ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯æƒ…å ±
        if current_epoch > 0:
            stats_lines.append(f"\nğŸ”„ Current: Epoch {current_epoch}")
        
        return '\n'.join(stats_lines)
    
    def _update_progress_log(self):
        """ã‚¿ã‚¤ãƒãƒ¼ã§å‘¼ã³å‡ºã•ã‚Œã€executorã®å‡ºåŠ›ã‚’å–å¾—ã—ã¦UIã‚’æ›´æ–°"""
        from kohya_gui.lora_gui import executor
        
        if executor.is_running():
            output = executor.get_output(last_n_lines=50)  # ã‚ˆã‚Šå¤šãã®ãƒ­ã‚°ã‚’è¡¨ç¤º
            full_output = executor.get_output(last_n_lines=500)  # çµ±è¨ˆç”¨ã«å…¨ãƒ­ã‚°å–å¾—
            epoch_stats = self._parse_epoch_stats(full_output)
            
            if output:
                return (
                    gr.Textbox(value=output),
                    gr.Textbox(value=epoch_stats) if epoch_stats else gr.Textbox(),
                    gr.Timer(active=True)
                )
            else:
                return (
                    gr.Textbox(value="Training in progress..."),
                    gr.Textbox(),
                    gr.Timer(active=True)
                )
        else:
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ‚äº†
            output = executor.get_output(last_n_lines=30)
            full_output = executor.get_output(last_n_lines=500)
            epoch_stats = self._parse_epoch_stats(full_output)
            
            # çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª
            exit_code = executor.process.poll() if executor.process else None
            if exit_code is not None and exit_code != 0:
                final_msg = output + f"\n\nâŒ Training failed! (Exit code: {exit_code})"
                status_msg = "âŒ Error" if not epoch_stats else epoch_stats + f"\n\nâŒ Error (code: {exit_code})"
            else:
                final_msg = output + "\n\nâœ… Training completed!" if output else "âœ… Training completed!"
                status_msg = epoch_stats + "\n\nâœ… Complete!" if epoch_stats else ""
            
            return (
                gr.Textbox(value=final_msg),
                gr.Textbox(value=status_msg) if status_msg else gr.Textbox(),
                gr.Timer(active=False)
            )
    
    def _wait_and_stop_timer(self):
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ‚äº†ã‚’å¾…ã£ã¦ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢ã—ã€ãƒœã‚¿ãƒ³çŠ¶æ…‹ã‚’å¾©å…ƒ"""
        from kohya_gui.lora_gui import executor
        
        while executor.is_running():
            import time
            time.sleep(1)
        
        # æœ€çµ‚å‡ºåŠ›ã‚’å–å¾—
        output = executor.get_output(last_n_lines=30)
        full_output = executor.get_output(last_n_lines=500)
        epoch_stats = self._parse_epoch_stats(full_output)
        
        # çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª
        exit_code = executor.process.poll() if executor.process else None
        if exit_code is not None and exit_code != 0:
            final_msg = output + f"\n\nâŒ Training failed! (Exit code: {exit_code})"
            status_msg = "âŒ Error" if not epoch_stats else epoch_stats + f"\n\nâŒ Error (code: {exit_code})"
        else:
            final_msg = output + "\n\nâœ… Training completed!" if output else "âœ… Training completed!"
            status_msg = epoch_stats + "\n\nâœ… Complete!" if epoch_stats else ""
        
        return (
            gr.Button(visible=True),   # train_button
            gr.Button(visible=False),  # stop_button
            gr.Timer(active=False),    # timer
            gr.Textbox(value=final_msg),  # output_log
            gr.Textbox(value=status_msg) if status_msg else gr.Textbox()  # epoch_stats
        )
    
    def _stop_training(self):
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åœæ­¢"""
        from kohya_gui.lora_gui import executor
        
        # åœæ­¢å‰ã«çµ±è¨ˆã‚’å–å¾—
        full_output = executor.get_output(last_n_lines=500)
        epoch_stats = self._parse_epoch_stats(full_output)
        
        executor.kill_command()
        
        output = executor.get_output(last_n_lines=30)
        final_msg = output + "\n\nâš ï¸ Training stopped by user." if output else "âš ï¸ Training stopped by user."
        
        return (
            gr.Button(visible=True),   # train_button
            gr.Button(visible=False),  # stop_button
            gr.Timer(active=False),    # timer
            gr.Textbox(value=final_msg),  # output_log
            gr.Textbox(value=epoch_stats + "\n\nâš ï¸ Stopped") if epoch_stats else gr.Textbox()  # epoch_stats
        )
    
    def _get_all_inputs(self):
        """ã™ã¹ã¦ã®å…¥åŠ›è¦ç´ ã‚’ãƒªã‚¹ãƒˆã§è¿”ã™ï¼ˆtrain_modelé–¢æ•°ã®å¼•æ•°é †ï¼‰"""
        return [
            # UI inputs
            self.pretrained_model_name_or_path,
            self.train_data_dir,
            self.output_name,
            self.output_dir,
            self.learning_rate,
            self.text_encoder_lr,
            self.network_dim,
            self.network_alpha,
            self.epoch,
            self.max_train_steps,
            self.max_resolution,
            self.train_batch_size,
            self.cache_latents,
            self.cache_latents_to_disk,
            self.save_model_as,
            self.save_precision
        ]
    
    def _check_config_changed(self, *args):
        """UIã®å€¤ãŒconfig.tomlã¨ç•°ãªã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã€ãƒœã‚¿ãƒ³ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        
        Tab.select() ã«ã‚ˆã‚‹å¤‰æ›´ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ãŸã‚ã€config.toml ã¨æ¯”è¼ƒã€‚
        å€¤ãŒç•°ãªã‚‹å ´åˆã®ã¿ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã™ã‚‹ã€‚
        """
        try:
            # config.toml ã‚’èª­ã¿è¾¼ã¿
            config = MINIMAL_DEFAULT_CONFIG.copy()
            user_config = load_user_config()
            config.update(user_config)
            
            
            # UIå€¤ã‚’å–å¾—
            ui_values = {
                'pretrained_model_name_or_path': args[0] if args[0] else '',
                'train_data_dir': args[1] if args[1] else '',
                'output_name': args[2] if args[2] is not None else '',
                'output_dir': args[3] if args[3] is not None else './outputs',
                'learning_rate': str(args[4]) if args[4] else '0.0001',
                'text_encoder_lr': str(args[5]) if args[5] else '0.00005',
                'network_dim': int(args[6]) if args[6] else 16,
                'network_alpha': int(args[7]) if args[7] else 16,
                'epoch': int(args[8]) if args[8] else 6,
                'max_train_steps': int(args[9]) if args[9] else 1600,
                'max_resolution': str(args[10]) if args[10] else '512,512',
                'train_batch_size': int(args[11]) if args[11] else 1,
                'cache_latents': bool(args[12]) if args[12] is not None else True,
                'cache_latents_to_disk': bool(args[13]) if args[13] is not None else False,
                'save_model_as': args[14] if args[14] else 'safetensors',
                'save_precision': args[15] if args[15] else 'fp16'
            }
            
            # æ¯”è¼ƒï¼ˆä¸€éƒ¨ã®å€¤ã¯å‹ã‚’æƒãˆã‚‹ï¼‰
            is_changed = False
            for key, ui_value in ui_values.items():
                config_value = config.get(key, '')
                
                # å‹ã‚’æƒãˆã¦æ¯”è¼ƒ
                if key in ['learning_rate', 'text_encoder_lr']:
                    # æµ®å‹•å°æ•°ç‚¹ã®æ¯”è¼ƒ
                    try:
                        ui_float = float(ui_value)
                        config_float = float(config_value) if config_value else 0.0
                        if abs(ui_float - config_float) > 1e-10:
                            is_changed = True
                            break
                    except (ValueError, TypeError):
                        is_changed = True
                        break
                elif isinstance(ui_value, bool):
                    config_bool = bool(config_value) if config_value is not None else False
                    if ui_value != config_bool:
                        is_changed = True
                        break
                elif isinstance(ui_value, int):
                    try:
                        config_int = int(config_value) if config_value else 0
                        if ui_value != config_int:
                            is_changed = True
                            break
                    except (ValueError, TypeError):
                        is_changed = True
                        break
                else:
                    if str(ui_value) != str(config_value):
                        is_changed = True
                        break
            
            if is_changed:
                return gr.update(value="ğŸ’¾ Save Config *", variant="primary")
            else:
                return gr.update(value="Save Config", variant="secondary")
        except Exception as e:
            log.warning(f"Config change check failed: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ãªã„
            return gr.update()
    
    def get_ui_outputs(self):
        """Tab.select()ã®outputsã¨ã—ã¦ä½¿ç”¨ã™ã‚‹UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
        return [
            self.pretrained_model_name_or_path,
            self.train_data_dir,
            self.output_name,
            self.output_dir,
            self.learning_rate,
            self.text_encoder_lr,
            self.network_dim,
            self.network_alpha,
            self.epoch,
            self.max_train_steps,
            self.max_resolution,
            self.train_batch_size,
            self.cache_latents,
            self.cache_latents_to_disk,
            self.save_model_as,
            self.save_precision,
            self.save_config_button  # ã‚¿ãƒ–é¸æŠæ™‚ã«ãƒœã‚¿ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
        ]
    
    def load_and_update_ui(self):
        """
        ã‚¿ãƒ–é¸æŠæ™‚ã«DEFAULTâ†’CONFIGã®é †ã§èª­ã¿è¾¼ã¿ã€UIã‚’æ›´æ–°
        
        è¨­è¨ˆåŸå‰‡:
        - å¸¸ã«åŒã˜ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆDEFAULTâ†’CONFIGä¸Šæ›¸ãï¼‰ã‚’é€šã‚‹
        - CONFIGã®æœ‰ç„¡ã«é–¢ã‚ã‚‰ãšåŒã˜ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’é€šã‚‹ã“ã¨ã§ãƒã‚°ã‚’æ¸›ã‚‰ã™
        
        Returns:
            tuple: gr.update()ã®ã‚¿ãƒ—ãƒ«ï¼ˆget_ui_outputs()ã®é †åºã¨ä¸€è‡´ï¼‰
        """
        # 1. DEFAULTã§åˆæœŸåŒ–
        config = MINIMAL_DEFAULT_CONFIG.copy()
        
        # 2. CONFIGã§ä¸Šæ›¸ã
        user_config = load_user_config()
        config.update(user_config)
        
        log.info(f"UI updated with config: {len(user_config)} user settings applied")
        
        # 3. text_encoder_lr ã‚’å°æ•°è¡¨è¨˜ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        text_encoder_lr_value = config.get('text_encoder_lr', config.get('learning_rate', 0.0001) * 0.5)
        text_encoder_lr_str = f"{float(text_encoder_lr_value):.5f}".rstrip('0').rstrip('.')
        
        # 4. gr.update()ã§UIã‚’æ›´æ–°ï¼ˆget_ui_outputs()ã®é †åºã¨ä¸€è‡´ï¼‰
        return (
            gr.update(value=config.get('pretrained_model_name_or_path', '')),
            gr.update(value=config.get('train_data_dir', '')),
            gr.update(value=config.get('output_name', '')),
            gr.update(value=config.get('output_dir', './outputs')),
            gr.update(value=str(config.get('learning_rate', 0.0001))),
            gr.update(value=text_encoder_lr_str),
            gr.update(value=config.get('network_dim', 16)),
            gr.update(value=config.get('network_alpha', 16)),
            gr.update(value=config.get('epoch', 6)),
            gr.update(value=config.get('max_train_steps', 1600)),
            gr.update(value=config.get('max_resolution', '512,512')),
            gr.update(value=config.get('train_batch_size', 1)),
            gr.update(value=config.get('cache_latents', True)),
            gr.update(value=config.get('cache_latents_to_disk', False)),
            gr.update(value=config.get('save_model_as', 'safetensors')),
            gr.update(value=config.get('save_precision', 'fp16')),
            gr.update(value="Save Config", variant="secondary")  # ãƒœã‚¿ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
        )
    
    def generate_captions(
        self,
        caption_text: str,
        train_data_dir: str,
        overwrite: bool
    ) -> str:
        """
        å›ºå®šã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’å…¨ç”»åƒã«ä¸€æ‹¬ç”Ÿæˆ
        
        Specification_001.md â‘¥ Captionä¸€æ‹¬ç”Ÿæˆï¼ˆé‡è¦ï¼‰ã®è¦ä»¶ã‚’æº€ãŸã™
        
        Args:
            caption_text: å›ºå®šã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            train_data_dir: å­¦ç¿’ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ï¼ˆImage folderã§æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‚’è‡ªå‹•ä½¿ç”¨ï¼‰
            overwrite: æ—¢å­˜ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ä¸Šæ›¸ãã™ã‚‹ã‹
            
        Returns:
            str: ç”Ÿæˆçµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        try:
            # å…¥åŠ›æ¤œè¨¼
            if not caption_text or not caption_text.strip():
                return "ã‚¨ãƒ©ãƒ¼: ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            
            if not train_data_dir or not train_data_dir.strip():
                return "ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ï¼ˆImage folderï¼‰ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
            
            # ãƒ‘ã‚¹ã®æ­£è¦åŒ–
            train_data_dir_path = os.path.normpath(train_data_dir.strip())
            
            if not os.path.exists(train_data_dir_path):
                return f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {train_data_dir_path}"
            
            if not os.path.isdir(train_data_dir_path):
                return f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã¯ãƒ•ã‚©ãƒ«ãƒ€ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {train_data_dir_path}"
            
            # kohya_ssã®ä»•æ§˜: train_data_dirã®ä¸‹ã«ã‚ã‚‹ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆ1å€‹ï¼‰ã‚’è‡ªå‹•æ¤œå‡º
            subfolders = [
                f
                for f in os.listdir(train_data_dir_path)
                if os.path.isdir(os.path.join(train_data_dir_path, f))
            ]
            
            if len(subfolders) == 0:
                return f"ã‚¨ãƒ©ãƒ¼: {train_data_dir_path} ã®ä¸‹ã«ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚kohya_ssã®ä»•æ§˜ã«å¾“ã„ã€ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆä¾‹: 5_SATOMIï¼‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            
            if len(subfolders) > 1:
                return f"ã‚¨ãƒ©ãƒ¼: {train_data_dir_path} ã®ä¸‹ã«è¤‡æ•°ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {', '.join(subfolders)}ã€‚ä»Šå›ã¯1ã¤ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚"
            
            # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ï¼‰
            images_dir = os.path.join(train_data_dir_path, subfolders[0])
            log.info(f"Captionç”Ÿæˆå¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€: {images_dir}")
            
            # æ—¢å­˜ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªï¼ˆä¸Šæ›¸ãç¢ºèªï¼‰
            if not overwrite:
                import glob
                caption_files = glob.glob(os.path.join(images_dir, "*.txt"))
                if caption_files:
                    file_count = len(caption_files)
                    return f"è­¦å‘Š: æ—¢å­˜ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒ{file_count}å€‹è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ä¸Šæ›¸ãã™ã‚‹å ´åˆã¯ã€ŒOverwrite existing captionsã€ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚"
            
            # æ—¢å­˜ã®caption_imagesé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from kohya_gui.basic_caption_gui import caption_images
            
            # caption_imagesé–¢æ•°ã‚’å‘¼ã³å‡ºã—
            caption_images(
                caption_text=caption_text.strip(),
                images_dir=images_dir,
                overwrite=overwrite,
                caption_ext=".txt",
                prefix="",
                postfix="",
                find_text="",
                replace_text=""
            )
            
            # ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ç¢ºèª
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJpegç³»ï¼‰ã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}
            image_extensions_upper = {ext.upper() for ext in image_extensions}
            
            image_count = 0
            caption_count = 0
            
            # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ—æŒ™ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
            for filename in os.listdir(images_dir):
                file_path = os.path.join(images_dir, filename)
                if os.path.isfile(file_path):
                    # æ‹¡å¼µå­ã‚’å–å¾—ï¼ˆå°æ–‡å­—ã«å¤‰æ›ï¼‰
                    _, ext = os.path.splitext(filename)
                    ext_lower = ext.lower()
                    
                    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJpegç³»ï¼‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    if ext_lower in image_extensions or ext in image_extensions_upper:
                        image_count += 1
                    # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.txtï¼‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    elif ext_lower == '.txt':
                        caption_count += 1
            
            result_msg = f"âœ“ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†\n"
            result_msg += f"  ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJpegç³»ï¼‰: {image_count}å€‹\n"
            result_msg += f"  ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.txtï¼‰: {caption_count}å€‹"
            
            log.info(result_msg)
            return result_msg
            
        except Exception as e:
            error_msg = f"ã‚¨ãƒ©ãƒ¼: ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ - {str(e)}"
            log.error(error_msg)
            return error_msg
    
    def _generate_minimal_params(
        self,
        pretrained_model_name_or_path,
        train_data_dir,
        output_name,
        output_dir,
        learning_rate,
        text_encoder_lr,
        network_dim,
        network_alpha,
        epoch,
        max_train_steps,
        max_resolution,
        train_batch_size,
        cache_latents,
        cache_latents_to_disk,
        save_model_as,
        save_precision
    ) -> dict:
        """
        Minimalã‚¿ãƒ–ã®UIå…¥åŠ›å€¤ã‹ã‚‰16å€‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã§ç”Ÿæˆ
        
        Returns:
            dict: Minimalã‚¿ãƒ–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ï¼ˆ16å€‹ï¼‰
        """
        return {
            'pretrained_model_name_or_path': pretrained_model_name_or_path,
            'train_data_dir': train_data_dir,
            'output_name': output_name,
            'output_dir': output_dir,
            'learning_rate': float(learning_rate) if learning_rate else 0.0001,
            'text_encoder_lr': float(text_encoder_lr) if text_encoder_lr else 0.00005,
            'network_dim': int(network_dim) if network_dim else 16,
            'network_alpha': int(network_alpha) if network_alpha else 16,
            'epoch': int(epoch) if epoch else 6,
            'max_train_steps': int(max_train_steps) if max_train_steps else 0,
            'max_resolution': max_resolution if max_resolution else '512,512',
            'train_batch_size': int(train_batch_size) if train_batch_size else 1,
            'cache_latents': bool(cache_latents) if cache_latents is not None else True,
            'cache_latents_to_disk': bool(cache_latents_to_disk) if cache_latents_to_disk is not None else False,
            'save_model_as': save_model_as if save_model_as else 'safetensors',
            'save_precision': save_precision if save_precision else 'fp16'
        }
    
    def _get_training_defaults(self) -> dict:
        """
        Trainingã‚¿ãƒ–ã®UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸå€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰ã‚’å–å¾—
        
        æ³¨æ„: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ã€Œç”Ÿæˆã€ã™ã‚‹ã®ã§ã¯ãªãã€
        Trainingã‚¿ãƒ–ã®UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸå€¤ã¨åŒã˜å€¤ã‚’ä½¿ç”¨ã™ã‚‹
        
        Returns:
            dict: Trainingã‚¿ãƒ–ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¾æ›¸ï¼ˆ229å€‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        """
        # Trainingã‚¿ãƒ–ã®UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸå€¤ï¼ˆlora_gui.pyã‹ã‚‰å–å¾—ï¼‰
        # ImplementationSpecification_Design_Requirement_001_VERIFIED.md ã«åŸºã¥ã
        
        defaults = {
            # source model sectionï¼ˆtrain_modelé–¢æ•°ã®å¼•æ•°é †åºã«å¾“ã†ï¼‰
            'v2': False,
            'v_parameterization': False,
            'sdxl': True,  # SDXLå›ºå®šï¼ˆMinimalã‚¿ãƒ–ã¯SDXLå°‚ç”¨ï¼‰
            'flux1_checkbox': False,
            'dataset_config': '',
            'model_list': '',
            'training_comment': '',
            
            # folders section
            'logging_dir': '',
            'reg_data_dir': '',
            
            # basic training section
            'lr_scheduler': 'cosine',
            'lr_warmup': 10,
            'lr_warmup_steps': 0,
            'save_every_n_epochs': 0,
            'seed': '',
            'caption_extension': '.txt',
            'enable_bucket': False,
            'stop_text_encoder_training': 0,
            'min_bucket_reso': 256,
            'max_bucket_reso': 1024,
            'max_train_epochs': 0,
            'lr_scheduler_num_cycles': 1,
            'lr_scheduler_power': 1.0,
            'optimizer': 'adamw8bit',
            'optimizer_args': '',
            'lr_scheduler_args': '',
            'lr_scheduler_type': '',
            'max_grad_norm': 1.0,
            
            # accelerate launch section
            'mixed_precision': 'fp16',
            'num_cpu_threads_per_process': 1,
            'num_processes': 1,
            'num_machines': 1,
            'multi_gpu': False,
            'gpu_ids': '',
            'main_process_port': 29500,
            'dynamo_backend': '',
            'dynamo_mode': '',
            'dynamo_use_fullgraph': False,
            'dynamo_use_dynamic': False,
            'extra_accelerate_launch_args': '',
            
            # advanced training section
            'gradient_checkpointing': False,
            'fp8_base': False,
            'fp8_base_unet': False,
            'full_fp16': False,
            'highvram': False,
            'lowvram': False,
            'xformers': False,
            'shuffle_caption': False,
            'save_state': False,
            'save_state_on_train_end': False,
            'resume': '',
            'prior_loss_weight': 1.0,
            'color_aug': False,
            'flip_aug': False,
            'masked_loss': False,
            'clip_skip': 1,
            'gradient_accumulation_steps': 1,
            'mem_eff_attn': False,
            'max_token_length': 75,
            'max_data_loader_n_workers': 0,
            'keep_tokens': 0,
            'persistent_data_loader_workers': False,
            'bucket_no_upscale': False,
            'random_crop': False,
            'bucket_reso_steps': 64,
            'v_pred_like_loss': 0,
            'caption_dropout_every_n_epochs': 0,
            'caption_dropout_rate': 0,
            'noise_offset_type': 'original',
            'noise_offset': 0,
            'noise_offset_random_strength': False,
            'adaptive_noise_scale': 0,
            'multires_noise_iterations': 0,
            'multires_noise_discount': 0,
            'ip_noise_gamma': 0,
            'ip_noise_gamma_random_strength': 0,
            'additional_parameters': '',
            'loss_type': 'l2',
            'huber_schedule': 'snr',
            'huber_c': 0.1,
            'huber_scale': 0.1,
            'vae_batch_size': 0,
            'min_snr_gamma': 0,
            'save_every_n_steps': 0,
            'save_last_n_steps': 0,
            'save_last_n_steps_state': 0,
            'save_last_n_epochs': 0,
            'save_last_n_epochs_state': 0,
            'skip_cache_check': False,
            'log_with': '',
            'wandb_api_key': '',
            'wandb_run_name': '',
            'log_tracker_name': '',
            'log_tracker_config': '',
            'log_config': '',
            'scale_v_pred_loss_like_noise_pred': False,
            'full_bf16': False,
            'min_timestep': 0,
            'max_timestep': 1000,
            'vae': '',
            'weighted_captions': False,
            'debiased_estimation_loss': False,
            
            # sdxl parameters section
            'sdxl_cache_text_encoder_outputs': False,
            'sdxl_no_half_vae': False,
            
            # LoRA network section
            'text_encoder_lr': 0.00005,  # Minimalã‚¿ãƒ–ã§ä¸Šæ›¸ãã•ã‚Œã‚‹
            't5xxl_lr': 0,
            'unet_lr': 0.0001,
            'network_weights': '',
            'dim_from_weights': False,
            'network_dim': 16,  # Minimalã‚¿ãƒ–ã§ä¸Šæ›¸ãã•ã‚Œã‚‹
            'network_alpha': 16,  # Minimalã‚¿ãƒ–ã§ä¸Šæ›¸ãã•ã‚Œã‚‹
            'LoRA_type': 'Standard',
            'factor': -1,
            'bypass_mode': False,
            'dora_wd': False,
            'use_cp': False,
            'use_tucker': False,
            'use_scalar': False,
            'rank_dropout_scale': False,
            'constrain': 0.0,
            'rescaled': False,
            'train_norm': False,
            'decompose_both': False,
            'train_on_input': True,
            'conv_dim': 32,
            'conv_alpha': 1,
            'sample_every_n_steps': 0,
            'sample_every_n_epochs': 0,
            'sample_sampler': 'euler_a',
            'sample_prompts': '',
            'down_lr_weight': '',
            'mid_lr_weight': '',
            'up_lr_weight': '',
            'block_lr_zero_threshold': 0,
            'block_dims': '',
            'block_alphas': '',
            'conv_block_dims': '',
            'conv_block_alphas': '',
            'unit': 1,
            'scale_weight_norms': 1.0,
            'network_dropout': 0,
            'rank_dropout': 0,
            'module_dropout': 0,
            'LyCORIS_preset': 'full',
            'loraplus_lr_ratio': 0,
            'loraplus_text_encoder_lr_ratio': 0,
            'loraplus_unet_lr_ratio': 0,
            'train_lora_ggpo': False,
            'ggpo_sigma': 0.5,
            'ggpo_beta': 0.5,
            
            # huggingface section
            'huggingface_repo_id': '',
            'huggingface_token': '',
            'huggingface_repo_type': 'model',
            'huggingface_repo_visibility': 'private',
            'huggingface_path_in_repo': '',
            'save_state_to_huggingface': False,
            'resume_from_huggingface': False,
            'async_upload': False,
            
            # metadata section
            'metadata_author': '',
            'metadata_description': '',
            'metadata_license': '',
            'metadata_tags': '',
            'metadata_title': '',
            
            # Flux1 parameters
            'flux1_cache_text_encoder_outputs': False,
            'flux1_cache_text_encoder_outputs_to_disk': False,
            'ae': '',
            'clip_l': '',
            't5xxl': '',
            'discrete_flow_shift': 3.0,
            'model_prediction_type': 'epsilon',
            'timestep_sampling': 'leading',
            'split_mode': 'alternating',
            'train_blocks': 'all',
            't5xxl_max_token_length': 512,
            'enable_all_linear': False,
            'guidance_scale': 3.5,
            'mem_eff_save': False,
            'apply_t5_attn_mask': False,
            'split_qkv': False,
            'train_t5xxl': False,
            'cpu_offload_checkpointing': False,
            'blocks_to_swap': 4,
            'single_blocks_to_swap': 4,
            'double_blocks_to_swap': 4,
            'img_attn_dim': 0,
            'img_mlp_dim': 0,
            'img_mod_dim': 0,
            'single_dim': 0,
            'txt_attn_dim': 0,
            'txt_mlp_dim': 0,
            'txt_mod_dim': 0,
            'single_mod_dim': 0,
            'in_dims': '',
            'train_double_block_indices': '',
            'train_single_block_indices': '',
            
            # SD3 parameters
            'sd3_cache_text_encoder_outputs': False,
            'sd3_cache_text_encoder_outputs_to_disk': False,
            'sd3_fused_backward_pass': False,
            'clip_g': '',
            'clip_g_dropout_rate': 0,
            'sd3_clip_l': '',
            'sd3_clip_l_dropout_rate': 0,
            'sd3_disable_mmap_load_safetensors': False,
            'sd3_enable_scaled_pos_embed': False,
            'logit_mean': 0,
            'logit_std': 0,
            'mode_scale': 0,
            'pos_emb_random_crop_rate': 0,
            'save_clip': False,
            'save_t5xxl': False,
            'sd3_t5_dropout_rate': 0,
            'sd3_t5xxl': '',
            't5xxl_device': '',
            't5xxl_dtype': '',
            'sd3_text_encoder_batch_size': 1,
            'weighting_scheme': 'sigma_sqrt',
            'sd3_checkbox': False,
        }
        
        # SDXLé¡”LoRAç”¨ã®æœ€é©åŒ–æ¸ˆã¿ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’é©ç”¨
        defaults.update(MINIMAL_DEFAULT_CONFIG)
        defaults.update(SDXL_FACE_LORA_FIXED)
        
        return defaults
    
    def _merge_params(self, training_defaults: dict, minimal_params: dict) -> dict:
        """
        Trainingã‚¿ãƒ–ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ã€Minimalã‚¿ãƒ–ã§è¨­å®šã—ãŸå€¤ã‚’ä¸Šæ›¸ã
        
        Args:
            training_defaults: Trainingã‚¿ãƒ–ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¾æ›¸ï¼ˆ229å€‹ï¼‰
            minimal_params: Minimalã‚¿ãƒ–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ï¼ˆ16å€‹ï¼‰
            
        Returns:
            dict: ãƒãƒ¼ã‚¸å¾Œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ï¼ˆ229å€‹ï¼‰
        """
        # Trainingã‚¿ãƒ–ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ã€Minimalã‚¿ãƒ–ã®å€¤ã‚’ä¸Šæ›¸ã
        final_params = {**training_defaults, **minimal_params}
        return final_params
    
    def _build_settings_list(self, params: dict) -> list:
        """
        settings_list ã‚’æ§‹ç¯‰ï¼ˆTrainingã‚¿ãƒ–ã¨åŒã˜é †åºï¼‰
        
        Args:
            params: ãƒãƒ¼ã‚¸å¾Œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ï¼ˆ229å€‹ï¼‰
            
        Returns:
            list: train_modelé–¢æ•°ã«æ¸¡ã™settings_listï¼ˆ229å€‹ã®å®Ÿéš›ã®å€¤ï¼‰
        """
        from minimal.utils import build_settings_list_from_params
        return build_settings_list_from_params(params)
    
    def start_training(
        self,
        pretrained_model_name_or_path,
        train_data_dir, 
        output_name,
        output_dir,
        learning_rate,
        text_encoder_lr,
        network_dim,
        network_alpha,
        epoch,
        max_train_steps,
        max_resolution,
        train_batch_size,
        cache_latents,
        cache_latents_to_disk,
        save_model_as,
        save_precision
    ):
        """
        å­¦ç¿’é–‹å§‹ - Design_Requirement_001.md ã«åŸºã¥ãå®Ÿè£…ï¼ˆ5ã‚¹ãƒ†ãƒƒãƒ—ãƒ•ãƒ­ãƒ¼ï¼‰
        
        1. Minimalãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ16å€‹ï¼‰
        2. Trainingã‚¿ãƒ–ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—ï¼ˆUIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸå€¤ã€ç”Ÿæˆã—ãªã„ï¼‰
        3. Minimalãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸
        4. settings_list ã‚’æ§‹ç¯‰ï¼ˆtrain_modelé–¢æ•°ã®å¼•æ•°é †åºã¨å®Œå…¨ã«ä¸€è‡´ï¼‰
        5. train_model() é–¢æ•°ã‚’æ—¢å­˜ã¨åŒã˜æ–¹æ³•ã§å‘¼ã³å‡ºã™
        """
        import time
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®æˆ»ã‚Šå€¤ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆtrain_buttonè¡¨ç¤ºã€stop_buttonéè¡¨ç¤ºã€timeråœæ­¢ï¼‰
        def error_return(msg):
            return (
                gr.Button(visible=True),   # train_button ã‚’è¡¨ç¤º
                gr.Button(visible=False),  # stop_button ã‚’éè¡¨ç¤º
                gr.Textbox(),              # run_stateï¼ˆå¤‰æ›´ãªã—ï¼‰
                gr.Textbox(value=msg),     # training_summary: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                gr.Timer(active=False)     # timer: åœæ­¢
            )
        
        try:
            # å…¥åŠ›æ¤œè¨¼
            if not pretrained_model_name_or_path:
                return error_return("ã‚¨ãƒ©ãƒ¼: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹ãŒå¿…è¦ã§ã™")
            if not train_data_dir or not os.path.exists(train_data_dir):
                return error_return("ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãŒå¿…è¦ã§ã™")
            if not output_name:
                return error_return("ã‚¨ãƒ©ãƒ¼: å‡ºåŠ›åãŒå¿…è¦ã§ã™")
            if not output_dir:
                return error_return("ã‚¨ãƒ©ãƒ¼: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå¿…è¦ã§ã™")
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: Minimalãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ16å€‹ï¼‰
            minimal_params = self._generate_minimal_params(
                pretrained_model_name_or_path,
                train_data_dir,
                output_name,
                output_dir,
                learning_rate,
                text_encoder_lr,
                network_dim,
                network_alpha,
                epoch,
                max_train_steps,
                max_resolution,
                train_batch_size,
                cache_latents,
                cache_latents_to_disk,
                save_model_as,
                save_precision
            )
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: Trainingã‚¿ãƒ–ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—ï¼ˆUIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸå€¤ã€ç”Ÿæˆã—ãªã„ï¼‰
            training_defaults = self._get_training_defaults()
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: Minimalãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸
            final_params = self._merge_params(training_defaults, minimal_params)
            
            # æ³¨: down_lr_weight/up_lr_weight ã¯U-Netãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã®å­¦ç¿’ç‡é‡ã¿è¨­å®šç”¨ã€‚
            #     SDXLã§ã¯9å€‹ã®ãƒ–ãƒ­ãƒƒã‚¯ã«å¯¾å¿œã—ãŸã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šãƒªã‚¹ãƒˆãŒå¿…è¦ã€‚
            #     Text Encoderå­¦ç¿’ç‡ã¯ text_encoder_lr ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆ¥é€”è¨­å®šæ¸ˆã¿ã€‚
            #     ã“ã“ã§ã¯è¿½åŠ ã®ãƒ–ãƒ­ãƒƒã‚¯å˜ä½åˆ¶å¾¡ã¯è¡Œã‚ãªã„ã€‚
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: settings_list ã‚’æ§‹ç¯‰ï¼ˆtrain_modelé–¢æ•°ã®å¼•æ•°é †åºã¨å®Œå…¨ã«ä¸€è‡´ï¼‰
            settings_list = self._build_settings_list(final_params)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®æ¤œè¨¼ï¼ˆheadlessã¨print_onlyã‚’é™¤ã229å€‹ï¼‰
            import inspect
            from kohya_gui.lora_gui import train_model as tm_check
            expected_count = len(inspect.signature(tm_check).parameters) - 2  # headless, print_only ã‚’é™¤ã
            actual_count = len(settings_list)
            log.info(f"Parameter count verification: expected={expected_count}, actual={actual_count}")
            if actual_count != expected_count:
                log.warning(f"Parameter count mismatch! Expected {expected_count}, got {actual_count}")
            
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æƒ…å ±ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
            training_summary = self._generate_training_summary(
                pretrained_model_name_or_path,
                train_data_dir,
                output_name,
                output_dir,
                learning_rate,
                text_encoder_lr,
                network_dim,
                network_alpha,
                epoch,
                max_train_steps,
                max_resolution,
                train_batch_size,
                cache_latents,
                cache_latents_to_disk
            )
            
            # ã‚¹ãƒ†ãƒƒãƒ—5: train_model() é–¢æ•°ã‚’æ—¢å­˜ã¨åŒã˜æ–¹æ³•ã§å‘¼ã³å‡ºã™
            # headless, print_only ã¯ä½ç½®å¼•æ•°ã¨ã—ã¦æ¸¡ã™ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ã ã¨*settings_listã¨ç«¶åˆï¼‰
            from kohya_gui.lora_gui import train_model
            result = train_model(
                self.headless,  # ä½ç½®å¼•æ•°: headless
                False,          # ä½ç½®å¼•æ•°: print_only
                *settings_list  # æ®‹ã‚Šã®229å€‹ã®ä½ç½®å¼•æ•°
            )
            
            # train_model ã¯ (train_button, stop_button, run_state_value) ã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™
            if result:
                train_btn, stop_btn, run_state_textbox = result
                return (
                    train_btn,
                    stop_btn,
                    run_state_textbox,  # run_state: çŠ¶æ…‹ç®¡ç†ç”¨
                    gr.Textbox(value=training_summary),  # training_summary: ã‚µãƒãƒªãƒ¼è¡¨ç¤º
                    gr.Timer(active=True)  # timer: é€²æ—æ›´æ–°ã‚’é–‹å§‹
                )
            else:
                return error_return("å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
            
        except Exception as e:
            error_msg = f"ã‚¨ãƒ©ãƒ¼: {str(e)}"
            log.error(error_msg, exc_info=True)
            return error_return(error_msg)
    
    def _generate_training_summary(
        self,
        pretrained_model_name_or_path,
        train_data_dir,
        output_name,
        output_dir,
        learning_rate,
        text_encoder_lr,
        network_dim,
        network_alpha,
        epoch,
        max_train_steps,
        max_resolution,
        train_batch_size,
        cache_latents,
        cache_latents_to_disk
    ) -> str:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æƒ…å ±ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        import os
        from datetime import datetime
        
        # ç”»åƒæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        image_count = 0
        repeats = 0
        subfolder_name = ""
        if train_data_dir and os.path.exists(train_data_dir):
            for item in os.listdir(train_data_dir):
                item_path = os.path.join(train_data_dir, item)
                if os.path.isdir(item_path):
                    subfolder_name = item
                    # repeats_class å½¢å¼ã®ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰repeatsæ•°ã‚’å–å¾—
                    parts = item.split('_')
                    if parts and parts[0].isdigit():
                        repeats = int(parts[0])
                    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    for file in os.listdir(item_path):
                        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.bmp')):
                            image_count += 1
                    break
        
        total_steps = image_count * repeats * int(epoch) if repeats > 0 else 0
        effective_steps = min(total_steps, int(max_train_steps)) if int(max_train_steps) > 0 else total_steps
        
        lines = [
            "=" * 50,
            f"  ğŸš€ Training Started - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "=" * 50,
            "",
            "ğŸ“ Model & Data:",
            f"  â€¢ Checkpoint: {os.path.basename(pretrained_model_name_or_path)}",
            f"  â€¢ Training folder: {subfolder_name}",
            f"  â€¢ Images: {image_count} Ã— {repeats} repeats = {image_count * repeats} steps/epoch",
            f"  â€¢ Output: {output_name}",
            "",
            "âš™ï¸ Training Parameters:",
            f"  â€¢ Resolution: {max_resolution}",
            f"  â€¢ Batch size: {train_batch_size}",
            f"  â€¢ Epochs: {epoch}",
            f"  â€¢ Max train steps: {max_train_steps if int(max_train_steps) > 0 else 'Unlimited'}",
            f"  â€¢ Effective steps: ~{effective_steps}",
            "",
            "ğŸ“Š Learning Rates:",
            f"  â€¢ U-Net LR: {learning_rate}",
            f"  â€¢ Text Encoder LR: {text_encoder_lr}",
            "",
            "ğŸ”§ LoRA Settings:",
            f"  â€¢ Network dim (rank): {network_dim}",
            f"  â€¢ Network alpha: {network_alpha}",
            "",
            "ğŸ’¾ Cache Settings:",
            f"  â€¢ Cache latents: {cache_latents}",
            f"  â€¢ Cache to disk: {cache_latents_to_disk}",
            "",
            "=" * 50,
            "  Training in progress... Check console for details.",
            "=" * 50,
        ]
        
        return "\n".join(lines)
    
    def save_config(self, explicit_save: bool, *args):
        """è¨­å®šå€¤ã‚’config.tomlã«ä¿å­˜

        Args:
            explicit_save: True ã®å ´åˆã¯æ˜ç¤ºä¿å­˜ã¨ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
        """
        try:
            import toml
            
            is_explicit_save = bool(explicit_save)
            
            # ç¾åœ¨ã®è¨­å®šå€¤ã‚’å–å¾—
            # _get_all_inputs()ã®é †åºã«åˆã‚ã›ã¦å¼•æ•°ã‚’å–å¾—:
            # explicit_save ã¯åˆ¥ã®å¼•æ•°ã¨ã—ã¦æ¸¡ã•ã‚Œã‚‹ï¼ˆ*argsã«ã¯å«ã¾ã‚Œãªã„ï¼‰
            # args[0]: pretrained_model_name_or_path (_get_all_inputs()[0])
            # args[1]: train_data_dir (_get_all_inputs()[1])
            # args[2]: output_name (_get_all_inputs()[2])
            # args[3]: output_dir (_get_all_inputs()[3])
            # args[4]: learning_rate (_get_all_inputs()[4])
            # args[5]: text_encoder_lr (_get_all_inputs()[5])
            # args[6]: network_dim (_get_all_inputs()[6])
            # args[7]: network_alpha (_get_all_inputs()[7])
            # args[8]: epoch (_get_all_inputs()[8])
            # args[9]: max_train_steps (_get_all_inputs()[9])
            # args[10]: max_resolution (_get_all_inputs()[10])
            # args[11]: train_batch_size (_get_all_inputs()[11])
            # args[12]: cache_latents (_get_all_inputs()[12])
            # args[13]: cache_latents_to_disk (_get_all_inputs()[13])
            # args[14]: save_model_as (_get_all_inputs()[14])
            # args[15]: save_precision (_get_all_inputs()[15])
            
            config_data = {
                'model': {
                    'pretrained_model_name_or_path': args[0] if len(args) > 0 and args[0] else '',
                    'save_model_as': args[14] if len(args) > 14 and args[14] else 'safetensors',
                    'save_precision': args[15] if len(args) > 15 and args[15] else 'fp16'
                },
                'training_data': {
                    'train_data_dir': args[1] if len(args) > 1 and args[1] else '',
                    'max_resolution': str(args[10]) if len(args) > 10 and args[10] else "512,512",
                    'train_batch_size': int(args[11]) if len(args) > 11 and args[11] else 1
                },
                'training_params': {
                    'learning_rate': float(args[4]) if len(args) > 4 and args[4] else 0.0001,
                    'text_encoder_lr': float(args[5]) if len(args) > 5 and args[5] else 0.00005,
                    'network_dim': int(args[6]) if len(args) > 6 and args[6] else 16,
                    'network_alpha': int(args[7]) if len(args) > 7 and args[7] else 16,
                    'epoch': int(args[8]) if len(args) > 8 and args[8] else 6,
                    'max_train_steps': int(args[9]) if len(args) > 9 and args[9] else 1600,
                    'cache_latents': bool(args[12]) if len(args) > 12 and args[12] is not None else True,
                    'cache_latents_to_disk': bool(args[13]) if len(args) > 13 and args[13] is not None else False
                },
                'output': {
                    'output_name': args[2] if len(args) > 2 and args[2] is not None else '',
                    'output_dir': args[3] if len(args) > 3 and args[3] is not None else './outputs'
                }
            }
            
            # TOMLãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            with open(self.config_path, 'w', encoding='utf-8') as f:
                f.write("# SDXL Face LoRA Minimal Configuration\n")
                f.write("# SDXLé¡”LoRAå­¦ç¿’ç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š\n")
                f.write("# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦ã€UIã®åˆæœŸå€¤ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™\n\n")
                toml.dump(config_data, f)
            
            log.info(f"Settings saved to {self.config_path}")
            
            # æ˜ç¤ºçš„ãªä¿å­˜ã‹ã‚ªãƒ¼ãƒˆã‚»ãƒ¼ãƒ–ã‹ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¤‰ãˆã‚‹
            if is_explicit_save:
                return "è¨­å®šã‚’config.tomlã«ä¿å­˜ã—ã¾ã—ãŸ"
            else:
                return ""  # ã‚ªãƒ¼ãƒˆã‚»ãƒ¼ãƒ–ã®å ´åˆã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ãªã„
            
        except Exception as e:
            error_msg = f"è¨­å®šã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            log.error(error_msg)
            return error_msg
    
    def save_config_and_reset_button(self, explicit_save: bool, *args):
        """è¨­å®šã‚’ä¿å­˜ã—ã€Save Configãƒœã‚¿ãƒ³ã‚’å…ƒã«æˆ»ã™
        
        Returns:
            tuple: (output_log ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, ãƒœã‚¿ãƒ³æ›´æ–°)
        """
        result = self.save_config(explicit_save, *args)
        # ä¿å­˜æˆåŠŸæ™‚ã¯ãƒœã‚¿ãƒ³ã‚’å…ƒã«æˆ»ã™
        if "å¤±æ•—" not in result and "ã‚¨ãƒ©ãƒ¼" not in result:
            return result, gr.update(value="Save Config", variant="secondary")
        else:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’ç¶­æŒ
            return result, gr.update()
    
    def _convert_ui_to_train_args(
        self, 
        pretrained_model_name_or_path,
        train_data_dir,
        output_name,
        output_dir,
        learning_rate,
        text_encoder_lr,
        network_dim,
        network_alpha,
        epoch,
        max_train_steps,
        max_resolution,
        train_batch_size,
        cache_latents,
        cache_latents_to_disk,
        save_model_as,
        save_precision
    ):
        """UIã®å…¥åŠ›å€¤ã‚’æ—¢å­˜train_modelé–¢æ•°ã®å¼•æ•°å½¢å¼ã«å¤‰æ›"""
        
        # ãƒ—ãƒªã‚»ãƒƒãƒˆå€¤ã‚’ãƒ™ãƒ¼ã‚¹ã«è¨­å®š
        defaults = MINIMAL_DEFAULT_CONFIG.copy()
        fixed = SDXL_FACE_LORA_FIXED.copy()
        
        # UIã‹ã‚‰ã®å€¤ã§ä¸Šæ›¸ã
        ui_values = {
            'pretrained_model_name_or_path': pretrained_model_name_or_path,
            'train_data_dir': train_data_dir,
            'output_name': output_name,
            'output_dir': output_dir,
            'learning_rate': float(learning_rate),
            'epoch': int(epoch),
            'max_train_steps': int(max_train_steps) if int(max_train_steps) > 0 else 0,
            'max_resolution': max_resolution,
            'train_batch_size': int(train_batch_size),
            'cache_latents': cache_latents,
            'cache_latents_to_disk': cache_latents_to_disk,
            'save_model_as': save_model_as,
            'save_precision': save_precision,
            'network_dim': int(network_dim),
            'network_alpha': int(network_alpha),
        }
        
        # LoRA networkå¼•æ•°ã‚’è¨­å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªLoRAè¨­å®šï¼‰
        # æ³¨: down_lr_weight/up_lr_weight ã¯ãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã®å­¦ç¿’ç‡åˆ¶å¾¡ç”¨ã§ã€
        #     SDXLã§ã¯9å€‹ã®ãƒ–ãƒ­ãƒƒã‚¯ã«å¯¾å¿œã—ãŸãƒªã‚¹ãƒˆãŒå¿…è¦ã€‚
        #     Text Encoderå­¦ç¿’ç‡ã¯ text_encoder_lr ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è¨­å®šæ¸ˆã¿ã€‚
        network_args = ''  # ã‚·ãƒ³ãƒ—ãƒ«ãªLoRAè¨­å®šï¼ˆè¿½åŠ å¼•æ•°ãªã—ï¼‰
        
        # å…¨è¨­å®šã‚’ãƒãƒ¼ã‚¸
        final_config = {**defaults, **fixed, **ui_values}
        
        # networké–¢é€£ã®è¨­å®šã‚’è¿½åŠ 
        final_config['network_args'] = network_args
        final_config['network_module'] = 'networks.lora'
        
        # train_modelé–¢æ•°ã®å¼•æ•°é †åºã«åˆã‚ã›ã¦è¿”ã™ï¼ˆå…¨121å¼•æ•°ï¼‰
        return [
            self.headless,  # headless
            False,  # print_only
            # source model section
            final_config['pretrained_model_name_or_path'],
            final_config['v2'],
            final_config['v_parameterization'], 
            final_config['sdxl'],
            final_config['flux1_checkbox'],
            final_config['dataset_config'],
            final_config['save_model_as'],
            final_config['save_precision'],
            final_config['train_data_dir'],
            final_config['output_name'],
            final_config['model_list'],
            final_config['training_comment'],
            # folders section
            final_config['logging_dir'],
            '', # reg_data_dir (æ­£å‰‡åŒ–ç”»åƒã¯ä½¿ã‚ãªã„)
            final_config['output_dir'],
            # basic training section
            final_config['max_resolution'],
            final_config['learning_rate'],
            final_config['lr_scheduler'],
            final_config['lr_warmup'],
            final_config['lr_warmup_steps'],
            final_config['train_batch_size'],
            final_config['epoch'],
            final_config['save_every_n_epochs'],
            final_config['seed'],
            final_config['cache_latents'],
            final_config['cache_latents_to_disk'],
            final_config['caption_extension'],
            final_config['enable_bucket'],
            final_config['stop_text_encoder_training'],
            final_config['min_bucket_reso'],
            final_config['max_bucket_reso'],
            final_config['max_train_epochs'],
            final_config['max_train_steps'],
            final_config['lr_scheduler_num_cycles'],
            final_config['lr_scheduler_power'],
            final_config['optimizer'],
            final_config['optimizer_args'],
            final_config['lr_scheduler_args'],
            final_config['lr_scheduler_type'],
            final_config['max_grad_norm'],
            # accelerate launch section
            final_config['mixed_precision'],
            final_config['num_cpu_threads_per_process'],
            final_config['num_processes'],
            final_config['num_machines'],
            final_config['multi_gpu'],
            final_config['gpu_ids'],
            final_config['main_process_port'],
            final_config['dynamo_backend'],
            final_config['dynamo_mode'],
            final_config['dynamo_use_fullgraph'],
            final_config['dynamo_use_dynamic'],
            final_config['extra_accelerate_launch_args'],
            # advanced training section  
            final_config['gradient_checkpointing'],
            final_config['fp8_base'],
            final_config['fp8_base_unet'],
            final_config['full_fp16'],
            final_config['highvram'],
            final_config['lowvram'],
            final_config['xformers'],
            final_config['shuffle_caption'],
            final_config['save_state'],
            final_config['save_state_on_train_end'],
            final_config['resume'],
            final_config['prior_loss_weight'],
            final_config['color_aug'],
            final_config['flip_aug'], 
            final_config['masked_loss'],
            final_config['clip_skip'],
            final_config['gradient_accumulation_steps'],
            final_config['mem_eff_attn'],
            final_config['max_token_length'],
            final_config['max_data_loader_n_workers'],
            final_config.get('keep_tokens', 0),
            final_config.get('persistent_data_loader_workers', False),
            final_config.get('bucket_no_upscale', False),
            final_config.get('random_crop', False),
            final_config.get('bucket_reso_steps', 64),
            final_config.get('v_pred_like_loss', 0.0),
            final_config.get('caption_dropout_every_n_epochs', 0),
            final_config.get('caption_dropout_rate', 0.0),
            final_config.get('noise_offset_type', 'Original'),
            final_config.get('noise_offset', 0.0),
            final_config.get('noise_offset_random_strength', 0.0),
            final_config.get('adaptive_noise_scale', 0.0),
            final_config.get('multires_noise_iterations', 0),
            final_config.get('multires_noise_discount', 0.0),
            final_config.get('ip_noise_gamma', 0.0),
            final_config.get('ip_noise_gamma_random_strength', 0.0),
            final_config.get('additional_parameters', ''),
            final_config.get('loss_type', 'l2'),
            final_config.get('huber_schedule', 'snr'),
            final_config.get('huber_c', 0.1),
            final_config.get('huber_scale', 1.0),
            final_config.get('vae_batch_size', 1),
            final_config.get('min_snr_gamma', 0.0),
            final_config.get('save_every_n_steps', 0),
            final_config.get('save_last_n_steps', 0),
            final_config.get('save_last_n_steps_state', False),
            final_config.get('save_last_n_epochs', 0),
            final_config.get('save_last_n_epochs_state', False),
            final_config.get('skip_cache_check', False),
            final_config.get('log_with', ''),
            final_config.get('wandb_api_key', ''),
            final_config.get('wandb_run_name', ''),
            final_config.get('log_tracker_name', ''),
            final_config.get('log_tracker_config', ''),
            final_config.get('log_config', ''),
            final_config.get('scale_v_pred_loss_like_noise_pred', False),
            final_config.get('full_bf16', False),
            final_config.get('min_timestep', 0),
            final_config.get('max_timestep', 1000),
            final_config.get('vae', ''),
            final_config.get('weighted_captions', False),
        ]

def sdxl_simple_tab(headless: bool = False, config: Any = None, use_shell_flag: bool = False):
    """SDXL Simple ã‚¿ãƒ–ã‚’ä½œæˆã—ã¦è¿”ã™"""
    tab = SDXLSimpleTab(headless=headless, config=config, use_shell_flag=use_shell_flag)
    tab.create_ui()
    return tab