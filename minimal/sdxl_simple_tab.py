import gradio as gr
import os
from pathlib import Path
from typing import Any
import logging

# MinimalÁî®„Éó„É™„Çª„ÉÉ„ÉàË®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø
from minimal.presets import (
    SDXL_FACE_LORA_DEFAULTS,
    SDXL_FACE_LORA_FIXED,
    RESOLUTION_CHOICES,
    BATCH_SIZE_CHOICES,
    SAVE_MODEL_AS_CHOICES,
    SAVE_PRECISION_CHOICES
)

log = logging.getLogger(__name__)

# kohya-ss„Çπ„Çø„Ç§„É´„ÅÆ„Ç¢„Ç§„Ç≥„É≥
folder_symbol = "\U0001f4c2"  # üìÇ
save_style_symbol = "\U0001f4be"  # üíæ
document_symbol = "\U0001F4C4"  # üìÑ

class SDXLSimpleTab:
    """
    SDXLÈ°îLoRAÂ∞ÇÁî®„ÅÆÁ∞°ÊòìUI„Çø„Éñ
    Êó¢Â≠ò„ÅÆLoRA„Çø„Éñ„Å®Âêå„ÅòÂá¶ÁêÜ„Çí„ÄÅÁ∞°ÊΩî„Å™UI„ÅßÊìç‰Ωú„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ
    """
    
    def __init__(self, headless: bool = False, config: Any = None, use_shell_flag: bool = False):
        self.headless = headless
        self.config = config
        self.use_shell_flag = use_shell_flag
        
    def create_ui(self):
        """UI‰ΩúÊàêÔºàAccordionÂΩ¢Âºè„ÄÅÊó¢Â≠ò„Çπ„Çø„Ç§„É´„Å´Âêà„Çè„Åõ„ÇãÔºâ"""
        with gr.Column(variant="compact"):
            gr.Markdown("**SDXLÈ°îLoRAÂ∞ÇÁî®„ÅÆÁ∞°Êòì„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ** - ÂøÖË¶ÅÊúÄÂ∞èÈôê„ÅÆ„Éë„É©„É°„Éº„Çø„ÅßÂÆâÂÖ®„Å´Â≠¶Áøí")
            
            # Model Source
            with gr.Accordion("Model Source", open=True):
                with gr.Row():
                    self.pretrained_model_name_or_path = gr.Textbox(
                        label="SDXL Checkpoint path",
                        placeholder="SDXL„É¢„Éá„É´„ÅÆ„Éë„Çπ (.safetensors or .ckpt)",
                        value="",
                        interactive=True,
                        scale=3
                    )
                    model_file_button = gr.Button(
                        f"{folder_symbol}",
                        elem_id="model_file_button",
                        scale=1,
                        size="sm"
                    )
                
                with gr.Row():
                    self.save_model_as = gr.Dropdown(
                        label="Save trained model as",
                        choices=SAVE_MODEL_AS_CHOICES,
                        value=SDXL_FACE_LORA_DEFAULTS['save_model_as']
                    )
                    self.save_precision = gr.Dropdown(
                        label="Save precision", 
                        choices=SAVE_PRECISION_CHOICES,
                        value=SDXL_FACE_LORA_DEFAULTS['save_precision']
                    )
            
            # Training Data
            with gr.Accordion("Training Data", open=True):
                with gr.Row():
                    self.train_data_dir = gr.Textbox(
                        label="Image folder",
                        placeholder="Â≠¶ÁøíÁîªÂÉè„ÅåÂê´„Åæ„Çå„Çã„Éï„Ç©„É´„ÉÄ",
                        value="",
                        interactive=True,
                        scale=3
                    )
                    image_folder_button = gr.Button(
                        f"{folder_symbol}",
                        elem_id="image_folder_button",
                        scale=1,
                        size="sm"
                    )
                
                with gr.Row():
                    self.max_resolution = gr.Dropdown(
                        label="Resolution",
                        choices=RESOLUTION_CHOICES,
                        value=SDXL_FACE_LORA_DEFAULTS['max_resolution'],
                        info="Â≠¶ÁøíËß£ÂÉèÂ∫¶ÔºàÈ°îLoRA„ÅØ512x512Êé®Â•®Ôºâ"
                    )
                    self.train_batch_size = gr.Dropdown(
                        label="Batch size",
                        choices=BATCH_SIZE_CHOICES,
                        value=SDXL_FACE_LORA_DEFAULTS['train_batch_size'],
                        info="„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫Ôºà1Êé®Â•®Ôºâ"
                    )
            
            # Training Parameters  
            with gr.Accordion("Training Parameters", open=True):
                with gr.Row():
                    self.learning_rate = gr.Textbox(
                        label="Learning rate",
                        value=str(SDXL_FACE_LORA_DEFAULTS['learning_rate']),
                        info="Â≠¶ÁøíÁéáÔºàU-NetÁî®Ôºâ"
                    )
                    self.text_encoder_lr = gr.Textbox(
                        label="Text encoder learning rate",
                        value=str(SDXL_FACE_LORA_DEFAULTS['learning_rate'] * 0.5),  # ÂçäÂàÜÁ®ãÂ∫¶
                        info="Text EncoderÂ≠¶ÁøíÁéá"
                    )
                
                with gr.Row():
                    self.network_dim = gr.Number(
                        label="LoRA Rank (dim)",
                        value=SDXL_FACE_LORA_DEFAULTS['network_dim'],
                        minimum=1,
                        maximum=128,
                        step=1,
                        info="LoRA„ÅÆÊ¨°ÂÖÉÊï∞"
                    )
                    self.network_alpha = gr.Number(
                        label="LoRA Alpha",
                        value=SDXL_FACE_LORA_DEFAULTS['network_alpha'],
                        minimum=1,
                        maximum=128,
                        step=1,
                        info="LoRA„ÅÆ„Ç¢„É´„Éï„Ç°ÂÄ§"
                    )
                
                with gr.Row():
                    self.epoch = gr.Number(
                        label="Epochs",
                        value=SDXL_FACE_LORA_DEFAULTS['epoch'],
                        minimum=1,
                        maximum=100,
                        step=1
                    )
                    self.max_train_steps = gr.Number(
                        label="Max train steps",
                        value=SDXL_FACE_LORA_DEFAULTS['max_train_steps'],
                        minimum=0,
                        step=100,
                        info="0 = epochÊï∞„ÅÆ„Åø‰ΩøÁî®"
                    )
                
                with gr.Row():
                    self.cache_latents = gr.Checkbox(
                        label="Cache latents",
                        value=SDXL_FACE_LORA_DEFAULTS['cache_latents'],
                        info="latents„Çí„Ç≠„É£„ÉÉ„Ç∑„É•„Åó„Å¶È´òÈÄüÂåñ"
                    )
                    self.cache_latents_to_disk = gr.Checkbox(
                        label="Cache latents to disk",
                        value=SDXL_FACE_LORA_DEFAULTS['cache_latents_to_disk'],
                        info="„Éá„Ç£„Çπ„ÇØ„Ç≠„É£„ÉÉ„Ç∑„É•„ÅßVRAMÁØÄÁ¥Ñ"
                    )
            
            # Output
            with gr.Accordion("Output", open=True):
                with gr.Row():
                    self.output_name = gr.Textbox(
                        label="Output name",
                        placeholder="character_name_lora",
                        value="",
                        info="Âá∫Âäõ„Åô„ÇãLoRA„É¢„Éá„É´„ÅÆÂêçÂâç"
                    )
                
                with gr.Row():
                    self.output_dir = gr.Textbox(
                        label="Output folder",
                        placeholder="Âá∫Âäõ„Éï„Ç©„É´„ÉÄ",
                        value="./outputs",
                        scale=3
                    )
                    output_folder_button = gr.Button(
                        f"{folder_symbol}",
                        elem_id="output_folder_button",
                        scale=1,
                        size="sm"
                    )
            
            # Training Control
            with gr.Accordion("Training", open=True):
                with gr.Row():
                    self.train_button = gr.Button(
                        "Start training",
                        variant="primary",
                        scale=2
                    )
                    self.stop_button = gr.Button(
                        "Stop training",
                        variant="stop",
                        scale=1
                    )
                
                self.output_log = gr.Textbox(
                    label="Training output",
                    value="",
                    lines=15,
                    max_lines=30,
                    interactive=False,
                    show_copy_button=True
                )
            
            # „Ç§„Éô„É≥„ÉàÊé•Á∂ö
            self.train_button.click(
                fn=self.start_training,
                inputs=self._get_all_inputs(),
                outputs=[self.output_log],
                show_progress=True
            )
    
    def _get_all_inputs(self):
        """„Åô„Åπ„Å¶„ÅÆÂÖ•ÂäõË¶ÅÁ¥†„Çí„É™„Çπ„Éà„ÅßËøî„ÅôÔºàtrain_modelÈñ¢Êï∞„ÅÆÂºïÊï∞È†ÜÔºâ"""
        return [
            # UI inputs
            self.pretrained_model_name_or_path,
            self.train_data_dir,
            self.output_name,
            self.output_dir,
            self.learning_rate,
            self.text_encoder_lr,
            self.network_dim,
            self.network_alpha,
            self.epoch,
            self.max_train_steps,
            self.max_resolution,
            self.train_batch_size,
            self.cache_latents,
            self.cache_latents_to_disk,
            self.save_model_as,
            self.save_precision
        ]
    
    def start_training(
        self,
        pretrained_model_name_or_path,
        train_data_dir, 
        output_name,
        output_dir,
        learning_rate,
        text_encoder_lr,
        network_dim,
        network_alpha,
        epoch,
        max_train_steps,
        max_resolution,
        train_batch_size,
        cache_latents,
        cache_latents_to_disk,
        save_model_as,
        save_precision
    ):
        """
        Â≠¶ÁøíÈñãÂßãÔºàÊó¢Â≠ò„ÅÆtrain_modelÈñ¢Êï∞„ÇíÂëº„Å≥Âá∫„ÅóÔºâ
        UI„ÅÆÂÄ§„ÇíÊó¢Â≠òÈñ¢Êï∞„ÅÆÂºïÊï∞ÂΩ¢Âºè„Å´Â§âÊèõ„Åó„Å¶Ê∏°„Åô
        """
        try:
            # ÂÖ•ÂäõÊ§úË®º
            if not pretrained_model_name_or_path:
                return "„Ç®„É©„Éº: „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Éë„Çπ„ÅåÂøÖË¶Å„Åß„Åô"
            if not train_data_dir or not os.path.exists(train_data_dir):
                return "„Ç®„É©„Éº: ÊúâÂäπ„Å™ÁîªÂÉè„Éï„Ç©„É´„ÉÄ„ÅåÂøÖË¶Å„Åß„Åô"
            if not output_name:
                return "„Ç®„É©„Éº: Âá∫ÂäõÂêç„ÅåÂøÖË¶Å„Åß„Åô"
            if not output_dir:
                return "„Ç®„É©„Éº: Âá∫Âäõ„Éï„Ç©„É´„ÉÄ„ÅåÂøÖË¶Å„Åß„Åô"
            
            # Êó¢Â≠ò„ÅÆtrain_modelÈñ¢Êï∞„Çí„Ç§„É≥„Éù„Éº„Éà
            from kohya_gui.lora_gui import train_model
            
            # UI„Éë„É©„É°„Éº„Çø„ÇíÊó¢Â≠òÈñ¢Êï∞„ÅÆÂºïÊï∞ÂΩ¢Âºè„Å´Â§âÊèõ
            args = self._convert_ui_to_train_args(
                pretrained_model_name_or_path,
                train_data_dir,
                output_name, 
                output_dir,
                learning_rate,
                text_encoder_lr,
                network_dim,
                network_alpha,
                epoch,
                max_train_steps,
                max_resolution,
                train_batch_size,
                cache_latents,
                cache_latents_to_disk,
                save_model_as,
                save_precision
            )
            
            # Êó¢Â≠ò„ÅÆtrain_modelÈñ¢Êï∞„ÇíÂëº„Å≥Âá∫„Åó
            result = train_model(*args)
            
            return result if result else "Â≠¶Áøí„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü"
            
        except Exception as e:
            error_msg = f"„Ç®„É©„Éº: {str(e)}"
            log.error(error_msg)
            return error_msg
    
    def _convert_ui_to_train_args(
        self, 
        pretrained_model_name_or_path,
        train_data_dir,
        output_name,
        output_dir,
        learning_rate,
        text_encoder_lr,
        network_dim,
        network_alpha,
        epoch,
        max_train_steps,
        max_resolution,
        train_batch_size,
        cache_latents,
        cache_latents_to_disk,
        save_model_as,
        save_precision
    ):
        """UI„ÅÆÂÖ•ÂäõÂÄ§„ÇíÊó¢Â≠òtrain_modelÈñ¢Êï∞„ÅÆÂºïÊï∞ÂΩ¢Âºè„Å´Â§âÊèõ"""
        
        # „Éó„É™„Çª„ÉÉ„ÉàÂÄ§„Çí„Éô„Éº„Çπ„Å´Ë®≠ÂÆö
        defaults = SDXL_FACE_LORA_DEFAULTS.copy()
        fixed = SDXL_FACE_LORA_FIXED.copy()
        
        # UI„Åã„Çâ„ÅÆÂÄ§„Åß‰∏äÊõ∏„Åç
        ui_values = {
            'pretrained_model_name_or_path': pretrained_model_name_or_path,
            'train_data_dir': train_data_dir,
            'output_name': output_name,
            'output_dir': output_dir,
            'learning_rate': float(learning_rate),
            'epoch': int(epoch),
            'max_train_steps': int(max_train_steps) if int(max_train_steps) > 0 else 0,
            'max_resolution': max_resolution,
            'train_batch_size': int(train_batch_size),
            'cache_latents': cache_latents,
            'cache_latents_to_disk': cache_latents_to_disk,
            'save_model_as': save_model_as,
            'save_precision': save_precision,
            'network_dim': int(network_dim),
            'network_alpha': int(network_alpha),
        }
        
        # LoRA networkÂºïÊï∞„ÇíË®≠ÂÆö
        # Text EncoderÂ≠¶ÁøíÁéá„ÅÆË®≠ÂÆö
        if float(text_encoder_lr) != float(learning_rate):
            # Áï∞„Å™„ÇãÂ≠¶ÁøíÁéá„Çí‰ΩøÁî®„Åô„ÇãÂ†¥Âêà
            network_args = f'conv_dim={int(network_dim)} conv_alpha={int(network_alpha)} '
            network_args += f'down_lr_weight={float(text_encoder_lr)} up_lr_weight={float(learning_rate)}'
        else:
            # Âêå„ÅòÂ≠¶ÁøíÁéá„ÅÆÂ†¥Âêà„ÅØ„Ç∑„É≥„Éó„É´„Å´
            network_args = ''
        
        # ÂÖ®Ë®≠ÂÆö„Çí„Éû„Éº„Ç∏
        final_config = {**defaults, **fixed, **ui_values}
        
        # networkÈñ¢ÈÄ£„ÅÆË®≠ÂÆö„ÇíËøΩÂä†
        final_config['network_args'] = network_args
        final_config['network_module'] = 'networks.lora'
        
        # train_modelÈñ¢Êï∞„ÅÆÂºïÊï∞È†ÜÂ∫è„Å´Âêà„Çè„Åõ„Å¶Ëøî„ÅôÔºàÂÖ®121ÂºïÊï∞Ôºâ
        return [
            self.headless,  # headless
            False,  # print_only
            # source model section
            final_config['pretrained_model_name_or_path'],
            final_config['v2'],
            final_config['v_parameterization'], 
            final_config['sdxl'],
            final_config['flux1_checkbox'],
            final_config['dataset_config'],
            final_config['save_model_as'],
            final_config['save_precision'],
            final_config['train_data_dir'],
            final_config['output_name'],
            final_config['model_list'],
            final_config['training_comment'],
            # folders section
            final_config['logging_dir'],
            '', # reg_data_dir (Ê≠£ÂâáÂåñÁîªÂÉè„ÅØ‰Ωø„Çè„Å™„ÅÑ)
            final_config['output_dir'],
            # basic training section
            final_config['max_resolution'],
            final_config['learning_rate'],
            final_config['lr_scheduler'],
            final_config['lr_warmup'],
            final_config['lr_warmup_steps'],
            final_config['train_batch_size'],
            final_config['epoch'],
            final_config['save_every_n_epochs'],
            final_config['seed'],
            final_config['cache_latents'],
            final_config['cache_latents_to_disk'],
            final_config['caption_extension'],
            final_config['enable_bucket'],
            final_config['stop_text_encoder_training'],
            final_config['min_bucket_reso'],
            final_config['max_bucket_reso'],
            final_config['max_train_epochs'],
            final_config['max_train_steps'],
            final_config['lr_scheduler_num_cycles'],
            final_config['lr_scheduler_power'],
            final_config['optimizer'],
            final_config['optimizer_args'],
            final_config['lr_scheduler_args'],
            final_config['lr_scheduler_type'],
            final_config['max_grad_norm'],
            # accelerate launch section
            final_config['mixed_precision'],
            final_config['num_cpu_threads_per_process'],
            final_config['num_processes'],
            final_config['num_machines'],
            final_config['multi_gpu'],
            final_config['gpu_ids'],
            final_config['main_process_port'],
            final_config['dynamo_backend'],
            final_config['dynamo_mode'],
            final_config['dynamo_use_fullgraph'],
            final_config['dynamo_use_dynamic'],
            final_config['extra_accelerate_launch_args'],
            # advanced training section  
            final_config['gradient_checkpointing'],
            final_config['fp8_base'],
            final_config['fp8_base_unet'],
            final_config['full_fp16'],
            final_config['highvram'],
            final_config['lowvram'],
            final_config['xformers'],
            final_config['shuffle_caption'],
            final_config['save_state'],
            final_config['save_state_on_train_end'],
            final_config['resume'],
            final_config['prior_loss_weight'],
            final_config['color_aug'],
            final_config['flip_aug'], 
            final_config['masked_loss'],
            final_config['clip_skip'],
            final_config['gradient_accumulation_steps'],
            final_config['mem_eff_attn'],
            final_config['max_token_length'],
            final_config['max_data_loader_n_workers'],
            final_config.get('keep_tokens', 0),
            final_config.get('persistent_data_loader_workers', False),
            final_config.get('bucket_no_upscale', False),
            final_config.get('random_crop', False),
            final_config.get('bucket_reso_steps', 64),
            final_config.get('v_pred_like_loss', 0.0),
            final_config.get('caption_dropout_every_n_epochs', 0),
            final_config.get('caption_dropout_rate', 0.0),
            final_config.get('noise_offset_type', 'Original'),
            final_config.get('noise_offset', 0.0),
            final_config.get('noise_offset_random_strength', 0.0),
            final_config.get('adaptive_noise_scale', 0.0),
            final_config.get('multires_noise_iterations', 0),
            final_config.get('multires_noise_discount', 0.0),
            final_config.get('ip_noise_gamma', 0.0),
            final_config.get('ip_noise_gamma_random_strength', 0.0),
            final_config.get('additional_parameters', ''),
            final_config.get('loss_type', 'l2'),
            final_config.get('huber_schedule', 'snr'),
            final_config.get('huber_c', 0.1),
            final_config.get('huber_scale', 1.0),
            final_config.get('vae_batch_size', 1),
            final_config.get('min_snr_gamma', 0.0),
            final_config.get('save_every_n_steps', 0),
            final_config.get('save_last_n_steps', 0),
            final_config.get('save_last_n_steps_state', False),
            final_config.get('save_last_n_epochs', 0),
            final_config.get('save_last_n_epochs_state', False),
            final_config.get('skip_cache_check', False),
            final_config.get('log_with', ''),
            final_config.get('wandb_api_key', ''),
            final_config.get('wandb_run_name', ''),
            final_config.get('log_tracker_name', ''),
            final_config.get('log_tracker_config', ''),
            final_config.get('log_config', ''),
            final_config.get('scale_v_pred_loss_like_noise_pred', False),
            final_config.get('full_bf16', False),
            final_config.get('min_timestep', 0),
            final_config.get('max_timestep', 1000),
            final_config.get('vae', ''),
            final_config.get('weighted_captions', False),
        ]

def sdxl_simple_tab(headless: bool = False, config: Any = None, use_shell_flag: bool = False):
    """SDXL Simple „Çø„Éñ„Çí‰ΩúÊàê„Åó„Å¶Ëøî„Åô"""
    tab = SDXLSimpleTab(headless=headless, config=config, use_shell_flag=use_shell_flag)
    tab.create_ui()
    return tab